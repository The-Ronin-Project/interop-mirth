## Mirth and Aidbox (Devbox) running in the same docker compose.
services:

  ## Mirth
  mc:
    # image: docker-proxy.devops.projectronin.io/ronin/base/mirth-base:3.11.0
    build: './mirth'
    container_name: mirth-connect
    env_file:
      - envs/mirth.env
    environment:
      VMOPTIONS: "-Xmx2G"
    ports: # Mirth and Mirth Admin UI
      - 8080:8080/tcp
      - 8443:8443/tcp
    volumes: # Do not modify
      - "./appdata:/opt/connect/appdata"       # Mirth general use
      - "./custom-lib:/opt/connect/custom-lib" # Mirth general use
      - "./custom-ext:/opt/connect/custom-extensions"   # Mirth plug-ins or extensions
      - "./doc:/opt/connect/doc"                        # Mirth server configuration (i.e. Java 9+)
      - "./conf/log4j.properties:/opt/connect/conf/log4j.properties"    # Mirth logging settings
      - "./interop:/opt/connect/interop"       # Ronin interop JAR and other interop resources
      - "./xml/read:/data/xml/read"            # Ronin DiagramChannel
      - "./xml/done:/data/xml/done"            # Ronin DiagramChannel
      - "./xml/error:/data/xml/error"          # Ronin DiagramChannel
      - "./xml/write:/data/xml/write"          # Ronin DiagramChannel
    depends_on:
      mirth-db:
        condition: service_started
      devbox:
        condition: service_healthy
      mockehrmysql:
        condition: service_healthy
      liquibase-ehr:
        condition: service_completed_successfully
      liquibase-queue:
        condition: service_completed_successfully
      mockehr:
        condition: service_started
      mock-server:
        condition: service_started
    healthcheck:
      test: [ "CMD", "curl", "-k", "-X", "GET", "https://mc:8443/api/server/resources", "-H", "\"X-Requested-With: OpenAPI\"", "-u", "admin:admin" ]
      timeout: 5s
      retries: 10

  ehr-data-authority:
    restart: on-failure
    image: docker-proxy.devops.projectronin.io/ehr-data-authority:latest
    ports:
      - "8083:8080"
    environment:
      SPRING_DATASOURCE_URL: "jdbc:mysql://ehrdauser:ThePassword@mockehrmysql:3306/dataauthority-db"
      AUTH0_AUDIENCE: "https://ehr.dev.projectronin.io"
      SPRING_SECURITY_OAUTH2_RESOURCESERVER_JWT_ISSUER_URI: "http://mock-oauth2:8080/ehr"
      OCI_INFX_REGISTRY_FILE: "DataNormalizationRegistry/v3/registry.json"
      KAFKA_PUBLISH_SOURCE: "ehr-data-authority"
      KAFKA_RETRIEVE_GROUPID: "ehr-data-authority_group"
      KAFKA_RETRIEVE_SERVICEID: "ehr-data-authority"
    env_file:
      - envs/mirth.env
    depends_on:
      devbox:
        condition: service_healthy
      kafka:
        condition: service_started
      mockehrmysql:
        condition: service_healthy
      mock-oauth2:
        condition: service_started

  mirth-db:
    image: postgres
    container_name: mirth-db
    env_file:
      - envs/mirth.env
    volumes:
      - ./data-mcpg:/data  # Avoid collision with "data" folder used by devbox and devbox-db
    expose:
      - 5433
    command: -p 5433 # Avoid collision with default port 5432 used by devbox-db

  ## Aidbox (Devbox)
  devbox:
    image: healthsamurai/devbox:2206-lts
    container_name: mirth-devbox
    depends_on:
      - "devbox-db"
    links:
      - "devbox-db:database"
    ports:
      - "${AIDBOX_PORT}:${AIDBOX_PORT}"
    env_file:
      - envs/aidbox.env
    environment:
      - AIDBOX_LICENSE_ID
      - AIDBOX_LICENSE_KEY
    volumes:
      - ./config:/var/config
      - ./data:/data # Avoid collision with "data" folder used by devbox-db and mirth-db
    healthcheck:
      test: [ "CMD", "curl", "-H", "\"Content-Type: application/json\"", "-H", "\"Accept: application/json\"", "-X", "POST", "-d", "\"{\\\"query\\\":\\\"query { PractitionerList { id } }\\\"}\"", "http://localhost:8888/$$graphql", "-u", "client:secret" ]
      timeout: 5s
      retries: 30

  devbox-db:
    image: healthsamurai/aidboxdb:13.2
    platform: linux/amd64
    container_name: mirth-devbox-db
    ports:
      - "${AIDBOX_PGHOSTPORT}:${AIDBOX_PGPORT}"
    env_file:
      - envs/aidbox.env
    volumes:
      - ./data-dbpg:/data # Avoid collision with "data" folder used by devbox and mirth-db

  # MySQL Database.
  # It is name "mockehrmysql" due to the mock-ehr-init script requiring this name
  # Creates multiple DB schemas and users, which can be seen in db/init/01-databases.sql
  mockehrmysql:
    image: mysql/mysql-server
    container_name: mirth-mysql-db
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_ROOT_HOST: '%'
    ports:
      - "3306:3306"
    volumes:
      - ./db/init:/docker-entrypoint-initdb.d
    healthcheck:
      test: [ "CMD", "mysqladmin" ,"ping", "-h", "localhost", "-u", "ehr", "-psecret" ]
      timeout: 5s
      retries: 30

  ## Schema updates + starter data
  liquibase-ehr:
    image: docker-proxy.devops.projectronin.io/interop-ehr-liquibase:dev
    container_name: mirth-ehr-liquibase
    environment:
      - JDBC_URL=jdbc:mysql://$EHR_DB_USERNAME:$EHR_DB_PASSWORD@mockehrmysql:3306/interop-ehr
      - DATA_LOAD=db/changelog/insertTestData.yaml
      - AO_SANDBOX_KEY
    volumes:
      - ./db/changelog/:/liquibase/changelog/db/changelog
    depends_on:
      mockehrmysql:
        condition: service_healthy

  mockehr:
    restart: on-failure
    image: docker-proxy.devops.projectronin.io/interop-mock-ehr:latest
    container_name: mirth-mock-ehr
    environment:
      - MOCK_EHR_DB_HOST=mockehrmysql
      - MOCK_EHR_DB_PORT=33060
      - MOCK_EHR_DB_NAME=mock_ehr_db
      - MOCK_EHR_DB_USER=springuser
      - MOCK_EHR_DB_PASS=ThePassword
    ports:
      - "8081:8080" # HTTP Port
      - "1011:1011" # TCP Port
    depends_on:
      mockehrmysql:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-k", "-X", "GET", "localhost:8080/fhir/r4/metadata", "-H", "\accept: application/fhir+json", ]
      timeout: 5s
      retries: 30

  liquibase-queue:
    image: docker-repo.devops.projectronin.io/interop-queue-liquibase:dev
    container_name: mirth-queue-liquibase
    environment:
      - JDBC_URL=jdbc:mysql://${QUEUE_DB_USERNAME}:${QUEUE_DB_PASSWORD}@mockehrmysql:3306/interop-queue
    depends_on:
      mockehrmysql:
        condition: service_healthy

  local-proxy:
    image: docker-proxy.devops.projectronin.io/interop-proxy-server:latest
    container_name: mirth-proxy-sever
    env_file:
      - envs/proxy.env
    environment:
      - AO_SANDBOX_KEY
      - SERVICE_CALL_JWT_SECRET
    ports:
      - 8082:8080
    volumes:
      - ./proxy/:/config
    depends_on:
      liquibase-queue:
        condition: service_completed_successfully
      mockehrmysql:
        condition: service_healthy
      liquibase-ehr:
        condition: service_completed_successfully
    healthcheck:
      test: [ "CMD", "curl", "-k", "-X", "GET", "localhost:8080/actuator/health" ]
      timeout: 5s
      retries: 30
  kafka:
    image: docker-proxy.devops.projectronin.io/wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: >-
        LISTENER_DOCKER_INTERNAL://kafka:19092,
        LISTENER_DOCKER_EXTERNAL://127.0.0.1:9092
      KAFKA_LISTENERS: >-
        LISTENER_DOCKER_INTERNAL://:19092,
        LISTENER_DOCKER_EXTERNAL://:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: >-
        LISTENER_DOCKER_INTERNAL:PLAINTEXT,
        LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_HEAP_OPTS: "-Xmx1G"
    depends_on:
      - zookeeper

  # available at http://localhost:8090. Can view topics and messages
  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8090:8080"
    restart: always
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:19092

  mock-server:
    platform: linux/amd64
    image: "docker-proxy.devops.projectronin.io/mockserver/mockserver:latest"
    container_name: mirth-mock-oci
    volumes:
      - "./mock-oci/config/mockserver.properties:/config/mockserver.properties"
      - "./mock-oci/expectations:/expectations"
    ports:
      - 1081:443
    networks:
      default:
        aliases:
          - oraclecloud.com
          - objectstorage.us-phoenix-1.oraclecloud.com
          - dev.projectronin.io

  zookeeper:
    image: docker-proxy.devops.projectronin.io/zookeeper
    ports:
      - "2181:2181"
    environment:
      - KAFKA_ADVERTISED_HOST_NAME=zookeeper
  # This is just to force servers to be healthy before completion. The docker compose up --wait functionality appears to fail due to the stopped containers.
  wait:
    image: hello-world:latest
    depends_on:
      mc:
        condition: service_healthy
      local-proxy:
        condition: service_healthy
      mockehr:
        condition: service_healthy
      devbox:
        condition: service_healthy

  vault:
    build:
      context: ./vault
    volumes:
      - ./vault/data:/vault/data
    environment:
      VAULT_ADDR: "http://0.0.0.0:8200"
      VAULT_API_ADDR: "http://0.0.0.0:8200"
      VAULT_DEV_ROOT_TOKEN_ID: "root"
      VAULT_DEV_LISTEN_ADDRESS: "0.0.0.0:8200"
    ports:
      - 8200:8200
    cap_add:
      - IPC_LOCK
    healthcheck:
      test: [ "CMD", "curl", "-k", "-X", "GET", "localhost:8200/v1/sys/health" ]
      timeout: 2s
      retries: 10

  vault-init:
    image: vault:latest
    volumes:
      - ./vault/secrets.json:/secrets.json
      - ./vault/policy.hcl:/policy.hcl
    entrypoint: [ "/bin/sh","-c" ]
    environment:
      VAULT_ADDR: "http://vault:8200"
    command:
      - |
        vault login "root"
        vault secrets enable -path=interop-mirth-connector -version=2 kv
        vault kv put -mount="interop-mirth-connector" dev @secrets.json
        vault policy write mirth /policy.hcl
        vault auth enable -path=approle-mirth-dev approle
        vault write -f auth/approle-mirth-dev/role/developer \policies="default","mirth"
        vault write -f auth/approle-mirth-dev/role/developer/role-id role_id="interops_role"
        vault write auth/approle-mirth-dev/role/developer/custom-secret-id secret_id="interops_secret"
    depends_on:
      vault:
        condition: service_healthy

  validation-server:
    restart: on-failure
    image: docker-proxy.devops.projectronin.io/interop-validation:latest
    environment:
      - SPRING_DATASOURCE_URL=jdbc:mysql://validationuser:ThePassword@mockehrmysql:3306/validation-db
      - AUTH0_AUDIENCE=https://interop-validation.dev.projectronin.io
      - SPRING_SECURITY_OAUTH2_RESOURCESERVER_JWT_ISSUER_URI=http://mock-oauth2:8080/validation
    ports:
      - "8084:8080"
    depends_on:
      mock-oauth2:
        condition: service_started

  mock-oauth2:
    image: ghcr.io/navikt/mock-oauth2-server:0.5.4
    ports:
      - "8085:8080"
    volumes:
      - ./ehrda:/host
    environment:
      - JSON_CONFIG_PATH=/host/mock-oauth2-config.json

secrets:
  mcserver_vmoptions:
    file: ./jvm-options/mcservice-java9+.vmoptions
